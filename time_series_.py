# -*- coding: utf-8 -*-
"""time series .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qnzXn9bi8bSQFQXVJJOq8o4pcIN_pstf
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime
from datetime import timedelta
from pandas.plotting import register_matplotlib_converters
from statsmodels.tsa.stattools import acf, pacf
from statsmodels.tsa.arima.model import ARIMA
register_matplotlib_converters()
from time import time

!pip install pmdarima

import scipy.io
mat = scipy.io.loadmat('HSI_Index.mat')
a = mat['data']

data = []
for i in a:
  for b in i:
    data.append(b)
data

series = pd.Series(data)
type(series)

series.head()

plt.figure(figsize=(10,4))
plt.plot(series)
plt.title('HSI', fontsize=20)
plt.ylabel('Sales', fontsize=16)
#for year in range(start_date.year,end_date.year):
    #plt.axvline(pd.to_datetime(str(year)+'-01-01'), color='k', linestyle='--', alpha=0.2)
#plt.axhline(lim_catfish_sales.mean(), color='r', alpha=0.2, linestyle='--')

first_diff = series.diff()

plt.figure(figsize=(20,10))
plt.plot(first_diff)
plt.title('First Difference of HSI', fontsize=20)
#plt.ylabel('Sales', fontsize=16)
#for year in range(start_date.year,end_date.year):
    #plt.axvline(pd.to_datetime(str(year)+'-01-01'), color='k', linestyle='--', alpha=0.2)
#plt.axhline(first_diff.mean(), color='r', alpha=0.2, linestyle='--')

log = np.log(series)

plt.figure(figsize=(20,10))
plt.plot(log)
#plt.title('Log of HSI', fontsize=20)
plt.ylabel('Sales', fontsize=16)

Ntest = 5
train = series[ : -Ntest ]
test = series[ -Ntest : ]

print(train)

print(test)

train_idx = series.index <= train.index[-1]
test_idx = series.index > train.index[-1]

arima = ARIMA(train, order = (5,1,5))

arima_result = arima.fit()

result = arima_result.predict(start=train.index[0],end = train.index[-1])

plt.figure(figsize=(10,4))

plt.plot(series)
plt.plot(result)
plt.title('HSI', fontsize=20)
plt.ylabel('Sales', fontsize=16)

prediction_result = arima_result.get_forecast(Ntest)

forecast = prediction_result.predicted_mean
result = result.append(forecast)

plt.figure(figsize=(100,20))

plt.plot(series)
plt.plot(result)
plt.title('HSI', fontsize=20)
plt.ylabel('Sales', fontsize=16)

"""# *AUTO ARIMA*"""

import pmdarima as pm

auto_arima_model = pm.auto_arima(train,
                                 trace = True,
                                 suppress_Warnings = True,
                                 seasonal = True,
                                 )

auto_arima_model.summary()

"""# Machin learning methods

"""

from sklearn.linear_model import LinearRegression
from sklearn.svm import SVR
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_percentage_error,r2_score

mldata = log.to_numpy()

T = 10
X = []
Y = []
for t in range(len(mldata) - T):
  x = mldata[t:t+T]
  X.append(x)
  y = mldata[t+T]
  Y.append(y)


X = np.array(X).reshape(-1,T)
Y = np.array(Y)
N = len(X)
print("X.shape",X.shape,'Y.shape',Y.shape)

ml_Xtrain , ml_Ytrain = X[:-Ntest], Y[:-Ntest]
ml_Xtest , ml_Ytest = X[-Ntest:],Y[-Ntest:]

lr = LinearRegression()
lr.fit(ml_Xtrain,ml_Ytrain)
lr.score(ml_Xtrain,ml_Ytrain)

lr.score(ml_Xtest,ml_Ytest)

train_idx = series.index <= train.index[-1]
test_idx = series.index > train.index[-1]

lr_1step_train = lr.predict(ml_Xtrain)
lr_1step_test = lr.predict(ml_Xtest)

plt.figure(figsize=(50,5))

#plt.plot(log)
plt.plot(ml_Ytest)
plt.plot(lr_1step_test)
plt.title('HSI', fontsize=20)
plt.ylabel('Sales', fontsize=16)
plt.legend()

"""# LSTM"""

import tensorflow as tf
from tensorflow.keras.layers import Dense,Input,GlobalMaxPooling1D,LSTM,GRU
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import ModelCheckpoint

!pip install -u scikit-learn

lstm_data = log.diff().dropna().to_numpy()

T = 10
X = []
Y = []

for t in range(len(lstm_data) - T):
  x = lstm_data[t:t+T]
  X.append(x)
  y = lstm_data[t+T]
  Y.append(y)

X = np.array(X).reshape(-1,T,1)
Y = np.array(Y)
N = len(X)
print("X.shape",X.shape,"Y.shape",Y.shape)

Xtrain,Ytrain = X[:-Ntest],Y[:-Ntest]
Xtest,Ytest = X[-Ntest:], Y[-Ntest:]

i = Input(shape=(T,1))
x = LSTM(24)(i)
x = Dense(1)(x)
model = Model(i,x)

model.summary()

model.compile(loss = 'mse',optimizer = 'adam')

r = model.fit(Xtrain,
              Ytrain,
              epochs = 100,
              validation_data=(Xtest,Ytest))

plt.plot(r.history['loss'], label = 'train loss')
plt.plot(r.history['val_loss'], label = 'test loss')
plt.legend();

train_idx[:T+1] = False

Ptrain = model.predict(Xtrain).flatten()
Ptest = model.predict(Xtest).flatten()

shiftlog = series.shift(1)

last_train = series.iloc[-1]

one_step_train = shiftlog[train_idx] + Ptrain
one_step_test = shiftlog[test_idx]+ Ptest

plt.figure(figsize=(20,20))

plt.plot(series)
plt.plot(one_step_train)
plt.plot(one_step_test)
plt.title('HSI', fontsize=20)
plt.ylabel('Sales', fontsize=16)
plt.legend()

multistep_predictions = []

last_x = Xtest[0]

while len(multistep_predictions) < Ntest:
  p = model.predict(last_x.reshape(1, last_x.shape[0], last_x.shape[1]))[0]

  multistep_predictions.append(p)

  last_x = np.roll(last_x,-1)
  last_x[-1] = p

multistep_temp = last_train + np.cumsum(multistep_predictions)

multistep_temp

multistep = shiftlog[test_idx]

multistep[2256] = multistep_temp[0]
#multistep[2257] = multistep_temp[1]
#multistep[2258] = multistep_temp[2]
#multistep[2259] = multistep_temp[3]
#multistep[2260] = multistep_temp[4]

multistep

one_step_test

plt.figure(figsize=(20,10))

#plt.plot(series)
#plt.plot(multistep)
plt.plot(one_step_test.values)
plt.title('HSI', fontsize=20)
plt.ylabel('Sales', fontsize=16)
plt.legend()

# multioutput supervised

#Tx = T
#Ty = Ntest
#X = []
#Y = []
#for t in range(len(lstm_data) - Tx - Ty + 1):
  #x = lstm_data[t:t+Tx]
  #X.append(x)
  #y = lstm_data[t+Tx:Tx+Ty]
  #Y.append(y)

#X = np.array(X).reshape(-1,Tx,1)
#Y = np.array(Y).reshape(-1,Ty)
#N = len(X)
#print("X.shape",X.shape,"Y.shape",Y.shape)

Tx = T
Ty = Ntest
X = []
Y = []
for t in range(len(lstm_data) - Tx - Ty + 1):
    x = lstm_data[t : t + Tx]
    y = lstm_data[t + Tx : t + Tx + Ty]

    # Check if both x and y have the same length
    if len(x) == Tx and len(y) == Ty:
        X.append(x)
        Y.append(y)

X = np.array(X).reshape(-1, Tx, 1)
Y = np.array(Y).reshape(-1, Ty)
N = len(X)

print("X.shape",X.shape,"Y.shape",Y.shape)

Xtrain_m, Ytrain_m = X[:-1] , Y[:-1]
Xtest_m , Ytest_m = X[-1:] , Y[-1:]

i = Input(shape = (Tx,1))
x = LSTM (24,return_sequences = True )(i)
x = GlobalMaxPooling1D()(x)
x = Dense(Ty)(x)
model = Model(i,x)

check_point = ModelCheckpoint(
    'best_model.h5',monitor = 'val_loss', save_best_only = True
)

model.compile(
    loss = 'mse',
    optimizer = 'adam'
)

r = model.fit(
    Xtrain_m,
    Ytrain_m,
    epochs=100,
    validation_data=(Xtest_m, Ytest_m),
    callbacks=[check_point],
)

plt.plot(r.history['loss'], label = 'train loss')
plt.plot(r.history['val_loss'], label = 'test loss')
plt.legend();

best_model = tf.keras.models.load_model('best_model.h5')

Ptrain = model.predict(Xtrain_m)
Ptest = model.predict(Xtest_m)

Ptrain.shape , Ptest.shape

Ptrain = Ptrain[:,0]
Ptest = Ptest[0]

multioutput = last_train + np.cumsum(Ptest)

plt.figure(figsize=(50,15))

plt.plot(series)
plt.plot(multistep)
plt.plot(one_step_test.values)
plt.plot(multioutput)
plt.title('HSI', fontsize=20)
plt.ylabel('Sales', fontsize=16)
plt.legend()

test_log_pass = series[-Ntest:]
#mape1 = mean_absolute_percentage_error(test_log_pass,multistep)
#print("multistep MAPE:",mape1)
mape2 = mean_absolute_percentage_error(test_log_pass,multioutput)
print("multioutput MAPE:",mape2)

from sklearn.metrics import mean_squared_error
#mse = mean_squared_error(test_log_pass, multistep)
#rmse1 = np.sqrt(mse)
mse2 = mean_squared_error(test_log_pass, multioutput)
rmse2 = np.sqrt(mse2)
#print(rmse1)
print(rmse2)

rmse = np.sqrt(np.mean((test_log_pass - multioutput)**2))

print("Root Mean Square Error (RMSE) using NumPy:", rmse)

test_log_pass

multistep